{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd24d36d",
   "metadata": {},
   "source": [
    "# Avances en el apartado del reconocimiento de voz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3028d62",
   "metadata": {},
   "source": [
    "### Instalación de la librería"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55a096",
   "metadata": {},
   "source": [
    "**Instalación de la librería a usar:**\n",
    "\n",
    "Nota: Usaremos la API de Google Cloud speech-to-text para hacer el reconocimiento de voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f756c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-speech in c:\\users\\usuario\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Collecting google-cloud-speech\n",
      "  Downloading google_cloud_speech-2.19.0-py2.py3-none-any.whl (273 kB)\n",
      "     -------------------------------------- 273.9/273.9 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-speech) (1.22.2)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-speech) (2.11.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-speech) (4.22.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.16.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.58.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.28.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.51.3)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.51.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (5.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.2.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.4.8)\n",
      "Installing collected packages: google-cloud-speech\n",
      "  Attempting uninstall: google-cloud-speech\n",
      "    Found existing installation: google-cloud-speech 2.18.0\n",
      "    Uninstalling google-cloud-speech-2.18.0:\n",
      "      Successfully uninstalled google-cloud-speech-2.18.0\n",
      "Successfully installed google-cloud-speech-2.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4129727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa61aa",
   "metadata": {},
   "source": [
    "**Creación de la variable de entorno:**\n",
    "\n",
    "Creamos una variable de entorno que apunta a la ubicación de un archivo Json que contiene la API key proveída por Google cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6f84a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/usuario/Jarvis/jarvis-381306-4975f3ce0efb.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0744190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/usuario/Jarvis/jarvis-381306-4975f3ce0efb.json\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82c58b",
   "metadata": {},
   "source": [
    "Para poder usar el reconocimiento de voz de la API debemos crear una variable `client`, una variable `audio` y una variable `config`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffffd948",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ee223af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_uri = \"gs://cloud-samples-data/speech/brooklyn_bridge.raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec45fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = speech.RecognitionAudio(uri=gcs_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36213b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code = \"en-US\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d17795",
   "metadata": {},
   "source": [
    "Usamos la función `recognize` para hacer el reconocimiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d69980dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how old is the Brooklyn Bridge\n"
     ]
    }
   ],
   "source": [
    "response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "#Para imprimir más de un resultado\n",
    "for i in response.results:\n",
    "    print(i.alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c46b30",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c30e82",
   "metadata": {},
   "source": [
    "### Reconocimiento de voz de archivos locales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdbe969",
   "metadata": {},
   "source": [
    "**Reconocimiento de voz de audios cortos:**\n",
    "\n",
    "Nota: Es posible hacer reconomiento de voz de archivos locales, pero estos archivos tienen una restricción de 60 segs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5785ba9",
   "metadata": {},
   "source": [
    "Hacemos una función para hacer el reconocimiento de archivos, pasándole la ruta de estos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddcda793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_voice(audio_path):\n",
    "    from google.cloud import speech\n",
    "    import io\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "    \n",
    "    with io.open(audio_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "        \n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    \n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        language_code=\"es-CO\"\n",
    "    )\n",
    "    \n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26491e",
   "metadata": {},
   "source": [
    "Ahora probamos la función apra ver qué tal funciona:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5f668",
   "metadata": {},
   "source": [
    "Nota: Los archivos pueden encontrarse en la carpeta Audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bf5d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola Me llamo Lucas tengo sueño y quiero dormir\n"
     ]
    }
   ],
   "source": [
    "responses = recognize_voice(\"C:/Users/usuario/Jarvis/Audios/Grabación2.wav\")\n",
    "\n",
    "for i in responses.results:\n",
    "    print(i.alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cf2d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Este es mi madre\n",
      " y aún hay en el campo\n",
      " te amo te amo te amo te amo\n"
     ]
    }
   ],
   "source": [
    "responses = recognize_voice(\"C:/Users/usuario/Jarvis/Audios/Grabación3.wav\")\n",
    "\n",
    "for i in responses.results:\n",
    "    print(i.alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33d7a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta es una Esta es una prueba de sonido para ver si el modelo reconoce bien las palabras\n"
     ]
    }
   ],
   "source": [
    "responses = recognize_voice(\"C:/Users/usuario/Jarvis/Audios/Grabación4.wav\")\n",
    "\n",
    "for i in responses.results:\n",
    "    print(i.alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f700bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esto es una pequeña prueba para ver que también hace el modelo la captación de las palabras no sé muy bien que decir por lo que procedería hacer un breve relato de mi día fui a comprar lentes pero estaban muy caros y no quería gastar tanto dinero así que me gasté como 100000 en mi novia XVI\n"
     ]
    }
   ],
   "source": [
    "responses = recognize_voice(\"C:/Users/usuario/Jarvis/Audios/Prueba IA.wav\")\n",
    "\n",
    "for i in responses.results:\n",
    "    print(i.alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb596e",
   "metadata": {},
   "source": [
    "Vemos que la API funciona bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c17f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf3eb2",
   "metadata": {},
   "source": [
    "### Reconocimiento de voz de archivos en la nube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b38d1",
   "metadata": {},
   "source": [
    "**Reconocimiento de voz de audios largos:**\n",
    "\n",
    "Nota: Se puede hacer el reconocimiento de voz de audios de duración mayor a 60 segs, pero no se puede hacer con audios locales.\n",
    "\n",
    "En este caso los audios deben estar en un bucket de google cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e1aea",
   "metadata": {},
   "source": [
    "Una función para hacer este reconocimiento de voz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d06bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_gcs(gcs_uri):\n",
    "    \"\"\"Asynchronously transcribes the audio file specified by the gcs_uri.\"\"\"\n",
    "    from google.cloud import speech\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "        print(\"Confidence: {}\".format(result.alternatives[0].confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36607cb8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b11c89e",
   "metadata": {},
   "source": [
    "### Reconocimiento de voz de transmisión continua"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d005ce",
   "metadata": {},
   "source": [
    "**Reconocimiento de voz de audios en transmisión:**\n",
    "\n",
    "Nota: El reconocimiento de audio de transmisión (el que necesitamos) solo está disponible a través de gRCP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fe59c",
   "metadata": {},
   "source": [
    "Instalamos e importamos las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de12bc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\usuario\\anaconda3\\lib\\site-packages (0.2.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bb334ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "import pyaudio\n",
    "from six.moves import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1ddcc",
   "metadata": {},
   "source": [
    "Creamos las variables `RATE` y `CHUNK` que nos servirán como parámetros y son las propiedades default del audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51eaa16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb3ad3",
   "metadata": {},
   "source": [
    "Ahora creamos la clase `MicrophoneStream` que servirá para hacer la transmisión de audio desde el micrófono conectado al dispositivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0975439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrophoneStream(object):\n",
    "     # Opens a recording stream as a generator yielding the audio chunks.\n",
    "    \n",
    "    def __init__(self, rate, chunk):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "        \n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            stream_callback=self._fill_buffer\n",
    "        )\n",
    "        \n",
    "        self.closed = False\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        \n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "        \n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "    \n",
    "#     Este es el método que hace el reconocimiento de la transmisión y genera las palabras.\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            chunk = self._buff.get()\n",
    "            \n",
    "            if chunk is None:\n",
    "                return \n",
    "            data = [chunk]\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    \n",
    "                    if chunk is None:\n",
    "                        return \n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "                    \n",
    "            yield b\"\".join(data)\n",
    "            \n",
    "    def stop(self):\n",
    "        self.closed = True\n",
    "        self._buff.put(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e4a69",
   "metadata": {},
   "source": [
    "En este punto es donde se hacen los llamados a la clase que acabamos de crear para poder inciar la trmansmisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaae6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bueno ahora sí\r"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    language_code = \"es-CO\"\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True\n",
    "    )\n",
    "# Se crea el objeto de tipo MicrophoneStream.\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        \n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content) \n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        listen_print_loop(responses)\n",
    "\n",
    "def listen_print_loop(responses):\n",
    "    num_chars_printed = 0\n",
    "\n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        result = response.results[0]\n",
    "\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "\n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            num_chars_printed = len(transcript)\n",
    "\n",
    "        else:\n",
    "            print(transcript + overwrite_chars)\n",
    "\n",
    "            if re.search(r\"\\b(Terminar|terminar)\\b\", transcript, re.I):\n",
    "                print(\"Finalizando transmisión...\")\n",
    "                break\n",
    "\n",
    "            num_chars_printed = 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
