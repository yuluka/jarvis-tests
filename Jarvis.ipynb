{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e873858",
   "metadata": {},
   "source": [
    "# Integración de reconocimiento de voz y chat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604267e",
   "metadata": {},
   "source": [
    "Estableciendo la API key necesaria para poder hacer uso de la IA de reconocimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb3dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las cosas necesarias para poder usar la IA de reconocimiento de voz.\n",
    "from google.cloud import speech\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32dda77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos la API key necesaria para usar google cloud speech-to-text.\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/usuario/Jarvis/jarvis-381306-4975f3ce0efb.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f558a",
   "metadata": {},
   "source": [
    "Definiendo los métodos necesarios para poder hacer el reconocimiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d983abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase MicrophoneStream para poder hacer el reconocimiento.\n",
    "import MicrophoneStream as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b8ac6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Las configuraciones y cosas necesarias para iniciar el reconocimiento de voz.\n",
    "def begin_streaming():\n",
    "    language_code = \"es-CO\"\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    \n",
    "    RATE = 16000 \n",
    "    CHUNK = int(RATE / 10)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True\n",
    "    )\n",
    "# Se crea el objeto de tipo MicrophoneStream.\n",
    "    with ms.MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        \n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content) \n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "# Genera las predicciones de lo que se ha dicho.\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "# Imprime las predicciones.\n",
    "        return combine_lines(listen_print_loop(responses))\n",
    "        \n",
    "# En donde se ejecuta el loop para escuchar y transcribir el audio.\n",
    "def listen_print_loop(responses):\n",
    "    num_chars_printed = 0\n",
    "    \n",
    "    last_transcription_time = time.time()\n",
    "    \n",
    "    transcription = []\n",
    "    \n",
    "    for response in responses:\n",
    "        \n",
    "# Verifica si hay resultados en la respuesta actual. Si no los hay, pasa a la siguiente respuesta.\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "# Si sí hay resultados, entonces selecciona el primer resultado (que es el mejor, si no me equivoco). \n",
    "        result = response.results[0]\n",
    "\n",
    "# Si no hay ninguna alternativa dentro del resultado actual, entonces pasa a revisar la siguiente respuesta.\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "# En caso de que sí hayan alternativas en el resultado, se captura la transcripción de la primera de estas. \n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "# Reescribe los caracteres de la predicción anteriror.\n",
    "        overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "\n",
    "# Si el servicio de transcripción aún está procesando el audio, se escribe la transcripción actual \n",
    "# en la consola y se sobrescribe la transcripción anterior.\n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            num_chars_printed = len(transcript)\n",
    "            \n",
    "#         if time.time()-last_transcription_time > 5:\n",
    "#             print(transcript + overwrite_chars)\n",
    "\n",
    "#             transcription.append(transcript + overwrite_chars)\n",
    "            \n",
    "#             break\n",
    "            \n",
    "# En caso de que sí sea el mensaje final, revisa si se ha dicho la palabra \"terminar\". Si es \n",
    "# así, la transmisión se detiene.\n",
    "        else:\n",
    "            print(transcript + overwrite_chars)\n",
    "            \n",
    "            transcription.append(transcript + overwrite_chars)\n",
    "            \n",
    "            if re.search(r\"\\b(Terminar|ornitorrinco)\\b\", transcript, re.I):\n",
    "                break\n",
    "            \n",
    "            if time.time()-last_transcription_time > 2 and not response.results[1:]:\n",
    "                break\n",
    "            last_transcription_time = time.time()\n",
    "\n",
    "            num_chars_printed = 0\n",
    "    \n",
    "#     return transcript\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a101f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_lines(lines):\n",
    "    total = \"\"\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        total += lines[i]\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07202f42",
   "metadata": {},
   "source": [
    "Estableciendo la API key necesaria para poder hacer uso de la API de OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad3ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las cosas necesarias para poder usar la API de OpenAI.\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd302cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos la API key necesaria para usar las cosas de OpenAI.\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f86b0f",
   "metadata": {},
   "source": [
    "Definiendo los métodos necesarios para poder iniciar un chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6e17d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historial de la conversación que se ha tenido.\n",
    "previous_messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"You are a helpful assistant called Jarvis. Refer the user as DIOS.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b00c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método encargado del chat. Recibe un prompt y el historial de la conversación previa.\n",
    "def chat(ask, previous_messages):\n",
    "    previous_messages += [\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": ask\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    chat1 = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=previous_messages\n",
    "    )\n",
    "    \n",
    "    previous_messages += [\n",
    "        {\n",
    "            \"role\": \"assistant\", \"content\": chat1.choices[0].message.content\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return chat1.choices[0].message.content, previous_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021fe34",
   "metadata": {},
   "source": [
    "Haciendo las cosas para pasar lo del reconocimiento de voz al chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf066606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def begin_voice_chat():\n",
    "    global previous_messages\n",
    "    \n",
    "    prompt = begin_streaming()\n",
    "    \n",
    "    prompt = prompt.replace(\"terminar\", \"\")\n",
    "    \n",
    "    print(\"Generando respuesta...\")\n",
    "    \n",
    "    answer, previous_messages = chat(prompt, previous_messages)\n",
    "    \n",
    "    print(answer)\n",
    "    \n",
    "    return prompt, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167a1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin_voice_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ff802",
   "metadata": {},
   "source": [
    "Integrando GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad016083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports de las cosas que se usarán para la GUI.\n",
    "import tkinter as tk\n",
    "from tkinter import END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09ebc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métodos que se usarán por la GUI.\n",
    "\n",
    "# Funciones para el efecto hover.\n",
    "def hover_on_send(event):\n",
    "    send_bttn.config(background='#3C3C3C', activebackground=\"#3C3C3C\")\n",
    "    \n",
    "def hover_off_send(event):\n",
    "    send_bttn.config(background=\"#333333\", activebackground=\"#333333\")\n",
    "\n",
    "def hover_on_talk(event):\n",
    "    talk_bttn.config(background='#3C3C3C', activebackground=\"#3C3C3C\")\n",
    "\n",
    "def hover_off_talk(event):\n",
    "    talk_bttn.config(background=\"#333333\", activebackground=\"#333333\")\n",
    "    \n",
    "# Funciones para el prompt del TextArea\n",
    "def hide_prompt(event):\n",
    "    if message_text.get(\"1.0\", \"end-1c\") == 'Digita tus palabras para Jarvis...':\n",
    "        message_text.delete(\"1.0\", \"end-1c\")\n",
    "        message_text.configure(fg='black')\n",
    "\n",
    "def show_prompt(event):\n",
    "    if message_text.get(\"1.0\", \"end-1c\") == '':\n",
    "        message_text.insert(\"1.0\", 'Digita tus palabras para Jarvis...')\n",
    "        message_text.configure(fg='grey')\n",
    "\n",
    "def on_click_send_bttn(event):\n",
    "    send_message()\n",
    "    change_focus()\n",
    "    \n",
    "def send_message():\n",
    "    message = message_text.get(\"1.0\", \"end-1c\")\n",
    "    \n",
    "    if message != 'Digita tus palabras para Jarvis...':\n",
    "        message_text.delete(\"1.0\", \"end-1c\")\n",
    "        append_message(message)\n",
    "        \n",
    "        if message != '':\n",
    "            global previous_messages\n",
    "\n",
    "            answer, previous_messages = chat(message, previous_messages)\n",
    "            display_answer(answer)\n",
    "\n",
    "def send_voice_message(message, answer):\n",
    "    if message != '':\n",
    "        append_message(message)\n",
    "        display_answer(answer)\n",
    "\n",
    "def append_message(message_to_append):\n",
    "    global user_icon\n",
    "    chat_area.image_create(END, image=user_icon)\n",
    "    \n",
    "    chat_area.config(state='normal')\n",
    "\n",
    "    chat_area.insert(END, \"  \" + message_to_append + \"\\n\\n\")\n",
    "    \n",
    "    chat_area.config(state='disabled')\n",
    "    \n",
    "def display_answer(answer):\n",
    "    global jarvis_icon\n",
    "    chat_area.image_create(END, image=jarvis_icon)\n",
    "    \n",
    "    chat_area.config(state='normal')\n",
    "    \n",
    "    chat_area.tag_configure(\"left\", justify=\"left\")\n",
    "    chat_area.insert(END, \"  \" + answer + \"\\n\\n\", \"left\")\n",
    "    \n",
    "    chat_area.config(state='disabled')\n",
    "    \n",
    "def on_click_talk_bttn(event):\n",
    "    change_focus()\n",
    "    message, answer = begin_voice_chat()\n",
    "    \n",
    "    send_voice_message(message, answer)\n",
    "    \n",
    "def change_focus():\n",
    "    if message_text == window.focus_get():\n",
    "        window.focus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7941550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images():\n",
    "    global jarvis_icon\n",
    "    jarvis_icon = tk.PhotoImage(file=\"GUI/antOutline-robot 1@1x.png\")\n",
    "    \n",
    "    global user_icon\n",
    "    user_icon = tk.PhotoImage(file=\"GUI/md-person_outline 1@1x.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc4e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volví solo por un momento Quiero ver si está funcionando algo correctamente Así que estoy haciendo un audio larguito Para probarlo gracias\n",
      "Generando respuesta...\n",
      "Entiendo. Si necesitas probar audio, puedes utilizar la librería Pyaudio de Python. Pyaudio es una interfaz para la biblioteca de audio PortAudio, lo que te permite reproducir y grabar audio directamente desde Python.\n",
      "\n",
      "Aquí hay un ejemplo simple de cómo reproducir un archivo de audio usando Pyaudio:\n",
      "\n",
      "```python\n",
      "import pyaudio\n",
      "import wave\n",
      "\n",
      "filename = \"audio.wav\"\n",
      "\n",
      "# Abre el archivo de audio\n",
      "wf = wave.open(filename, 'rb')\n",
      "\n",
      "# Configura la instancia de Pyaudio\n",
      "p = pyaudio.PyAudio()\n",
      "stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
      "                channels=wf.getnchannels(),\n",
      "                rate=wf.getframerate(),\n",
      "                output=True)\n",
      "\n",
      "# Lee y reproduce el audio\n",
      "data = wf.readframes(1024)\n",
      "while data:\n",
      "    stream.write(data)\n",
      "    data = wf.readframes(1024)\n",
      "\n",
      "# Cierra la instancia de Pyaudio y el archivo de audio\n",
      "stream.stop_stream()\n",
      "stream.close()\n",
      "p.terminate()\n",
      "wf.close()\n",
      "```\n",
      "\n",
      "En este ejemplo, el archivo de audio se abre utilizando la librería `wave`, se configura la instancia de Pyaudio y se reproduce el audio mediante la lectura del archivo de audio y la escritura de los datos de audio en el stream de Pyaudio.\n",
      "\n",
      "Espero que esto te sea útil para probar tu audio, DIOS. ¡Déjame saber si necesitas más ayuda!\n",
      "más bien recomiéndame porfa alguna librería o alguna app que pueda utilizar para convertir texto a voz y reproducirlo mediante python\n",
      "Generando respuesta...\n",
      "Hay varias opciones de librerías y aplicaciones que puedes utilizar en Python para convertir texto a voz. Aquí te menciono algunas:\n",
      "\n",
      "1. `gTTS`: es una librería que utiliza la API de Google Text-to-Speech para convertir texto en voz. Puedes instalarla mediante `pip install gTTS`. Aquí te presento un código de ejemplo:\n",
      "\n",
      "```python\n",
      "from gtts import gTTS\n",
      "import os\n",
      "\n",
      "tts = gTTS(\"Hola, esto es una prueba\")\n",
      "tts.save(\"voz.mp3\")\n",
      "\n",
      "os.system(\"mpg321 voz.mp3\")\n",
      "```\n",
      "\n",
      "En este código, primero se importa la clase `gTTS` de la librería `gtts`. Luego se crea una instancia de esta clase con el texto que se quiere convertir. Finalmente, la voz convertida se guarda en un archivo llamado `voz.mp3` y luego se utiliza el comando `mpg321` para reproducir el archivo.\n",
      "\n",
      "2. `pyttsx3`: es una librería que utiliza la API de Text-to-Speech de Microsoft para convertir texto en voz. Puedes instalarla mediante `pip install pyttsx3`. Aquí te presento un código de ejemplo:\n",
      "\n",
      "```python\n",
      "import pyttsx3\n",
      "\n",
      "engine = pyttsx3.init()\n",
      "engine.say(\"Hola, esto es una prueba\")\n",
      "engine.runAndWait()\n",
      "```\n",
      "\n",
      "En este código, primero se importa la librería `pyttsx3`. Luego se crea una instancia del objeto `Engine` y se utiliza el método `say` para decir el texto deseado. Finalmente, se llama al método `runAndWait` para que la voz se reproduzca.\n",
      "\n",
      "¡Espero que esto te sea útil, DIOS! Si necesitas más ayuda, no dudes en preguntarme.\n"
     ]
    }
   ],
   "source": [
    "# GUI.\n",
    "\n",
    "# Creaciónde una ventana.\n",
    "window = tk.Tk()\n",
    "window.geometry(\"1080x763\")\n",
    "window.title(\"Jarvis\")\n",
    "window.configure(background='#333333')\n",
    "\n",
    "# Crear el botón con una imagen\n",
    "photo = tk.PhotoImage(file=\"GUI/md-send 1@1x.png\")\n",
    "send_bttn = tk.Button(window, image=photo)\n",
    "\n",
    "send_bttn.place(x=864, y=655, width=108, height=108)\n",
    "send_bttn.configure(background='#333333', borderwidth=0, highlightthickness=0, cursor=\"hand2\")\n",
    "\n",
    "send_bttn.bind(\"<Enter>\", hover_on_send)\n",
    "send_bttn.bind(\"<Leave>\", hover_off_send)\n",
    "send_bttn.bind(\"<Button-1>\", on_click_send_bttn)\n",
    "\n",
    "# Crear el botón con una imagen\n",
    "photo_talk = tk.PhotoImage(file=\"GUI/md-mic_none 1@1x.png\")\n",
    "talk_bttn = tk.Button(window, image=photo_talk)\n",
    "\n",
    "talk_bttn.place(x=972, y=655, width=108, height=108)\n",
    "talk_bttn.configure(background='#333333', borderwidth=0, highlightthickness=0, cursor=\"hand2\")\n",
    "\n",
    "talk_bttn.bind(\"<Enter>\", hover_on_talk)\n",
    "talk_bttn.bind(\"<Leave>\", hover_off_talk)\n",
    "talk_bttn.bind(\"<Button-1>\", on_click_talk_bttn)\n",
    "\n",
    "# Crear textArea.\n",
    "message_text = tk.Text(window)\n",
    "message_text.place(x=5, y=677, height=63, width=853)\n",
    "message_text.configure(font=('Arial',16), fg='grey')\n",
    "\n",
    "message_text.insert(\"1.0\", 'Digita tus palabras para Jarvis...')\n",
    "\n",
    "message_text.bind(\"<FocusIn>\", hide_prompt)\n",
    "message_text.bind(\"<FocusOut>\", show_prompt)\n",
    "\n",
    "# Crear ChatArea.\n",
    "chat_area = tk.Text(window, wrap=\"word\")\n",
    "chat_area.place(x=3, y=3, height=652, width=1074)\n",
    "chat_area.configure(font=('Arial',16), fg='white', background='#333333', border=0, state='disabled', \n",
    "                    borderwidth=0, highlightthickness=1, highlightcolor='white')\n",
    "\n",
    "jarvis_icon = None\n",
    "user_icon = None\n",
    "create_images()\n",
    "\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
