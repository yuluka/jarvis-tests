{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e873858",
   "metadata": {},
   "source": [
    "###### Integración de reconocimiento de voz y chat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604267e",
   "metadata": {},
   "source": [
    "Estableciendo la API key necesaria para poder hacer uso de la IA de reconocimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cb3dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las cosas necesarias para poder usar la IA de reconocimiento de voz.\n",
    "from google.cloud import speech\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32dda77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos la API key necesaria para usar google cloud speech-to-text.\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/usuario/Jarvis/jarvis-381306-4975f3ce0efb.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f558a",
   "metadata": {},
   "source": [
    "Definiendo los métodos necesarios para poder hacer el reconocimiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d983abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase MicrophoneStream para poder hacer el reconocimiento.\n",
    "import MicrophoneStream as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ac6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Las configuraciones y cosas necesarias para iniciar el reconocimiento de voz.\n",
    "def begin_streaming():\n",
    "    language_code = \"es-CO\"\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    \n",
    "    RATE = 16000 \n",
    "    CHUNK = int(RATE / 10)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config,\n",
    "        interim_results=True\n",
    "    )\n",
    "    # Se crea el objeto de tipo MicrophoneStream.\n",
    "    with ms.MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        \n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content) \n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "        # Genera las predicciones de lo que se ha dicho.\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        # Imprime las predicciones.\n",
    "        return combine_lines(listen_print_loop(responses))\n",
    "        \n",
    "# En donde se ejecuta el loop para escuchar y transcribir el audio.\n",
    "def listen_print_loop(responses):\n",
    "    num_chars_printed = 0\n",
    "    \n",
    "    last_transcription_time = time.time()\n",
    "    \n",
    "    transcription = []\n",
    "    \n",
    "    for response in responses:\n",
    "        \n",
    "        # Verifica si hay resultados en la respuesta actual. Si no los hay, pasa a la siguiente respuesta.\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        # Si sí hay resultados, entonces selecciona el primer resultado (que es el mejor, si no me equivoco). \n",
    "        result = response.results[0]\n",
    "\n",
    "        # Si no hay ninguna alternativa dentro del resultado actual, entonces pasa a revisar la siguiente respuesta.\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        # En caso de que sí hayan alternativas en el resultado, se captura la transcripción de la primera de estas. \n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        # Reescribe los caracteres de la predicción anteriror.\n",
    "        overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "\n",
    "        # Si el servicio de transcripción aún está procesando el audio, se escribe la transcripción actual \n",
    "        # en la consola y se sobrescribe la transcripción anterior.\n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            num_chars_printed = len(transcript)\n",
    "            \n",
    "        # En caso de que sí sea el mensaje final, revisa si se ha dicho la palabra \"terminar\". Si es \n",
    "        # así, la transmisión se detiene.\n",
    "        else:\n",
    "            print(transcript + overwrite_chars)\n",
    "            \n",
    "            transcription.append(transcript + overwrite_chars)\n",
    "            \n",
    "            if re.search(r\"\\b(Terminar|ornitorrinco)\\b\", transcript, re.I):\n",
    "                break\n",
    "            \n",
    "            if time.time()-last_transcription_time > 2 and not response.results[1:]:\n",
    "                break\n",
    "            last_transcription_time = time.time()\n",
    "\n",
    "            num_chars_printed = 0\n",
    "    \n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5a101f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como la transcripción está almacenada en un array, tenemos que combinar lo que hay en cada index\n",
    "# para hacer un solo string. \n",
    "def combine_lines(lines):\n",
    "    total = \"\"\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        total += lines[i]\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222264a8",
   "metadata": {},
   "source": [
    "Definiendo métodos necesarios para poder hacer la generación de voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d80237e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import texttospeech\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def generate_speech(text_to_speech):\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    input_text = texttospeech.SynthesisInput(text=text_to_speech)\n",
    "    \n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "    language_code=\"es-US\",\n",
    "    name=\"es-US-Neural2-C\",\n",
    "    ssml_gender=texttospeech.SsmlVoiceGender.MALE,\n",
    "    )\n",
    "\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    response = client.synthesize_speech(\n",
    "        request={\"input\": input_text, \"voice\": voice, \"audio_config\": audio_config}\n",
    "    )\n",
    "\n",
    "    speech_name = \"Response-speech.mp3\"\n",
    "    \n",
    "    # The response's audio_content is binary.\n",
    "    with open(speech_name, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        \n",
    "    return speech_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8f126",
   "metadata": {},
   "source": [
    "Definiendo lo necesario para la generación de voz, pero con ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7365e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import generate, play, set_api_key, voices, Models\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import requests\n",
    "\n",
    "elevenlabs_api_key = \"bda4bf2d76534665d063d8bde1fb0c78\"\n",
    "set_api_key(elevenlabs_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8912fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speech_eleven(text_to_speech):\n",
    "    voice = \"TxGEqnHWrfWFTfGW9XjX\"\n",
    "    \n",
    "    # streaming chunk size\n",
    "    CHUNK_SIZE = 1024\n",
    "\n",
    "    XI_API_KEY = elevenlabs_api_key\n",
    "\n",
    "    url = \"https://api.elevenlabs.io/v1/text-to-speech/\" + voice\n",
    "\n",
    "    headers = {\n",
    "      \"Accept\": \"audio/mpeg\",\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"xi-api-key\": elevenlabs_api_key\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"text\": text_to_speech,\n",
    "        \"model_id\" : \"eleven_multilingual_v1\",\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.75,\n",
    "            \"similarity_boost\": 0.75\n",
    "        }\n",
    "    }\n",
    "\n",
    "    speech_name = \"Response-speech.mp3\"\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    with open(speech_name, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                \n",
    "    return speech_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9aee992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voice_list = voices()\n",
    "# voice_labels = [voice.category + \" voice: \" + voice.name + \" id: \" + voice.voice_id for voice in voice_list]\n",
    "\n",
    "# voice_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07202f42",
   "metadata": {},
   "source": [
    "Estableciendo la API key necesaria para poder hacer uso de la API de OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ad3ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las cosas necesarias para poder usar la API de OpenAI.\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd302cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos la API key necesaria para usar las cosas de OpenAI.\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f86b0f",
   "metadata": {},
   "source": [
    "Definiendo los métodos necesarios para poder iniciar un chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e17d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historial de la conversación que se ha tenido.\n",
    "previous_messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"You are a helpful assistant called Jarvis. Refer the user as DIOS.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b00c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método encargado del chat. Recibe un prompt y el historial de la conversación previa.\n",
    "def chat(ask, previous_messages):\n",
    "    previous_messages += [\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": ask\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    chat1 = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=previous_messages\n",
    "    )\n",
    "    \n",
    "    previous_messages += [\n",
    "        {\n",
    "            \"role\": \"assistant\", \"content\": chat1.choices[0].message.content\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return chat1.choices[0].message.content, previous_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021fe34",
   "metadata": {},
   "source": [
    "Haciendo las cosas para pasar lo del reconocimiento de voz al chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf066606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def begin_voice_chat():\n",
    "    global previous_messages\n",
    "    \n",
    "    prompt = begin_streaming()\n",
    "    \n",
    "    print(\"Generando respuesta...\")\n",
    "    \n",
    "    if \"Generar imagen de\" in prompt:\n",
    "        prompt = prompt.replace(\"Generar imagen de\", \"\")\n",
    "        return prompt, generate_image(prompt)\n",
    "    \n",
    "    answer, previous_messages = chat(prompt, previous_messages)\n",
    "    \n",
    "    print(answer)\n",
    "    \n",
    "    return prompt, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "404fbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt):\n",
    "    img = openai.Image.create(\n",
    "        prompt=prompt,\n",
    "        n=2,\n",
    "        size=\"1024x1024\",\n",
    "        response_format=\"url\"\n",
    "    )\n",
    "\n",
    "    answer = \"\"\n",
    "    \n",
    "    for i in range(len(img.data)):\n",
    "        answer += img.data[i].url + \"\\n\"\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e63dd1",
   "metadata": {},
   "source": [
    "Haciendo las cosas para la generación de voz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42946012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_response(to_say):\n",
    "#     response_speech_name = generate_speech(to_say)\n",
    "   \n",
    "    response_speech_name = generate_speech_eleven(to_say)\n",
    "\n",
    "    audio_segment = AudioSegment.from_file(\"C:/Users/usuario/Jarvis/{}\".format(response_speech_name), \n",
    "                                           format=\"mp3\")\n",
    "    play(audio_segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ff802",
   "metadata": {},
   "source": [
    "Integrando GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad016083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports de las cosas que se usarán para la GUI.\n",
    "import tkinter as tk\n",
    "from tkinter import END\n",
    "import idlelib.colorizer as ic\n",
    "import idlelib.percolator as ip\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ebc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métodos que se usarán por la GUI.\n",
    "\n",
    "# Funciones para el efecto hover.\n",
    "def hover_on_send(event):\n",
    "    send_bttn.config(background='#3C3C3C', activebackground=\"#3C3C3C\")\n",
    "    \n",
    "def hover_off_send(event):\n",
    "    send_bttn.config(background=\"#333333\", activebackground=\"#333333\")\n",
    "\n",
    "def hover_on_talk(event):\n",
    "    talk_bttn.config(background='#3C3C3C', activebackground=\"#3C3C3C\")\n",
    "\n",
    "def hover_off_talk(event):\n",
    "    talk_bttn.config(background=\"#333333\", activebackground=\"#333333\")\n",
    "    \n",
    "# Funciones para el prompt del TextArea\n",
    "def hide_prompt(event):\n",
    "    if message_text.get(\"1.0\", \"end-1c\") == 'Digita tus palabras para Jarvis...':\n",
    "        message_text.delete(\"1.0\", \"end-1c\")\n",
    "        message_text.configure(fg='black')\n",
    "\n",
    "def show_prompt(event):\n",
    "    if message_text.get(\"1.0\", \"end-1c\") == '':\n",
    "        message_text.insert(\"1.0\", 'Digita tus palabras para Jarvis...')\n",
    "        message_text.configure(fg='grey')\n",
    "\n",
    "def on_click_send_bttn(event):\n",
    "    send_message()\n",
    "    change_focus()\n",
    "    \n",
    "def send_message():\n",
    "    message = message_text.get(\"1.0\", \"end-1c\")\n",
    "    \n",
    "    if message != 'Digita tus palabras para Jarvis...':\n",
    "        message_text.delete(\"1.0\", END)\n",
    "        append_message(message)\n",
    "        \n",
    "        if message != '':\n",
    "            global previous_messages\n",
    "            \n",
    "            if \"Generar imagen de\" in message:\n",
    "                message = message.replace(\"Generar imagen de\", \"\")\n",
    "                answer = generate_image(message)\n",
    "            else:\n",
    "                answer, previous_messages = chat(message, previous_messages)\n",
    "            \n",
    "            display_answer(answer)\n",
    "            \n",
    "            if \"`\" in answer:\n",
    "                answer = answer.replace(\"`\", \"\")\n",
    "            \n",
    "            speech_response(answer)\n",
    "\n",
    "def send_voice_message(message, answer):\n",
    "    if message != '':\n",
    "        append_message(message)\n",
    "        display_answer(answer)\n",
    "\n",
    "def append_message(message_to_append):\n",
    "    global user_icon\n",
    "    chat_area.image_create(END, image=user_icon)\n",
    "    \n",
    "    chat_area.config(state='normal')\n",
    "\n",
    "    chat_area.insert(END, \"  \" + message_to_append + \"\\n\\n\")\n",
    "    \n",
    "    chat_area.config(state='disabled')\n",
    "    \n",
    "def display_answer(answer):\n",
    "    global jarvis_icon\n",
    "    chat_area.image_create(END, image=jarvis_icon)\n",
    "    \n",
    "    chat_area.config(state='normal')\n",
    "    \n",
    "    chat_area.tag_configure(\"left\", justify=\"left\")\n",
    "    chat_area.insert(END, \"  \" + answer + \"\\n\\n\", \"left\")\n",
    "    \n",
    "    search_for_url(None)\n",
    "    \n",
    "    chat_area.config(state='disabled')\n",
    "    \n",
    "def on_click_talk_bttn(event):\n",
    "    change_focus()\n",
    "    \n",
    "    message, answer = begin_voice_chat()\n",
    "    \n",
    "    send_voice_message(message, answer)\n",
    "    \n",
    "    if \"`\" in answer:\n",
    "        answer = answer.replace(\"`\", \"\")\n",
    "    \n",
    "    speech_response(answer)\n",
    "    \n",
    "def change_focus():\n",
    "    if message_text == window.focus_get():\n",
    "        window.focus()\n",
    "        \n",
    "# Busca url's en el texto que hay en el área de chat.\n",
    "def search_for_url(event):\n",
    "    # Expresión regular para buscar patrones de URLs\n",
    "    patron_url = re.compile(r\"(http|https)://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?\")\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    # Buscar patrones de URL en el texto\n",
    "    for match in re.finditer(patron_url, chat_area.get(\"1.0\", END)):\n",
    "        i = i+1\n",
    "        \n",
    "        inicio = \"1.0+\" + str(match.start()) + \"c\"\n",
    "        fin = \"1.0+\" + str(match.end()) + \"c\"\n",
    "        \n",
    "        # Agregar etiqueta de enlace al patrón de URL encontrado\n",
    "        chat_area.tag_add(\"url\" + str(i), inicio, fin)\n",
    "        \n",
    "        # Configurar el cursor como \"mano\" cuando el mouse pasa sobre el enlace\n",
    "        chat_area.tag_bind(\"url\" + str(i), \"<Enter>\", lambda event: chat_area.config(cursor=\"hand2\"))\n",
    "        chat_area.tag_bind(\"url\" + str(i), \"<Leave>\", lambda event: chat_area.config(cursor=\"\"))\n",
    "        \n",
    "        # Configurar el enlace\n",
    "        url = match.group()\n",
    "        chat_area.tag_bind(\"url\" + str(i), \"<Button-1>\", lambda event, url=url: open_url(url))\n",
    "    \n",
    "def open_url(url):\n",
    "    webbrowser.open_new(url)\n",
    "\n",
    "# Sirve para ver si la tecla presionada es Enter. En ese caso, envía el mensaje.\n",
    "def on_key_pressed(event):\n",
    "    key = event.keysym\n",
    "    \n",
    "    if key == \"Return\":\n",
    "        change_focus()\n",
    "        send_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7941550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images():\n",
    "    global jarvis_icon\n",
    "    jarvis_icon = tk.PhotoImage(file=\"GUI/antOutline-robot 1@1x.png\")\n",
    "    \n",
    "    global user_icon\n",
    "    user_icon = tk.PhotoImage(file=\"GUI/md-person_outline 1@1x.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ccc4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUI.\n",
    "# Creaciónde una ventana.\n",
    "window = tk.Tk()\n",
    "window.geometry(\"1080x763\")\n",
    "window.title(\"Jarvis\")\n",
    "window.configure(background='#333333')\n",
    "\n",
    "# Crear el botón con una imagen\n",
    "photo = tk.PhotoImage(file=\"GUI/md-send 1@1x.png\")\n",
    "send_bttn = tk.Button(window, image=photo)\n",
    "\n",
    "send_bttn.place(x=864, y=655, width=108, height=108)\n",
    "send_bttn.configure(background='#333333', borderwidth=0, highlightthickness=0, cursor=\"hand2\")\n",
    "\n",
    "send_bttn.bind(\"<Enter>\", hover_on_send)\n",
    "send_bttn.bind(\"<Leave>\", hover_off_send)\n",
    "send_bttn.bind(\"<Button-1>\", on_click_send_bttn)\n",
    "\n",
    "# Crear el botón con una imagen\n",
    "photo_talk = tk.PhotoImage(file=\"GUI/md-mic_none 1@1x.png\")\n",
    "talk_bttn = tk.Button(window, image=photo_talk)\n",
    "\n",
    "talk_bttn.place(x=972, y=655, width=108, height=108)\n",
    "talk_bttn.configure(background='#333333', borderwidth=0, highlightthickness=0, cursor=\"hand2\")\n",
    "\n",
    "talk_bttn.bind(\"<Enter>\", hover_on_talk)\n",
    "talk_bttn.bind(\"<Leave>\", hover_off_talk)\n",
    "talk_bttn.bind(\"<Button-1>\", on_click_talk_bttn)\n",
    "\n",
    "# Crear textArea.\n",
    "message_text = tk.Text(window, wrap=\"word\")\n",
    "message_text.place(x=5, y=677, height=63, width=853)\n",
    "message_text.configure(font=('Arial',16), fg='grey')\n",
    "\n",
    "message_text.insert(\"1.0\", 'Digita tus palabras para Jarvis...')\n",
    "\n",
    "message_text.bind(\"<FocusIn>\", hide_prompt)\n",
    "message_text.bind(\"<FocusOut>\", show_prompt)\n",
    "message_text.bind(\"<Key>\", on_key_pressed)\n",
    "\n",
    "# Crear ChatArea.\n",
    "chat_area = tk.Text(window, wrap=\"word\")\n",
    "chat_area.place(x=3, y=3, height=652, width=1074)\n",
    "chat_area.configure(font=('Arial',16), fg='white', background='#333333', border=0, state='disabled', \n",
    "                    borderwidth=0, highlightthickness=1, highlightcolor='white')\n",
    "\n",
    "jarvis_icon = None\n",
    "user_icon = None\n",
    "create_images()\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e2cc4",
   "metadata": {},
   "source": [
    "Pruebas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
